**3.2 딥러닝을 활용한 이미지 처리**  

**3.2.1 이미지 분류**  
- **이미지 분류**  
  - 입력된 이미지를 사전에 정의된 클래스 중 하나로 분류하는 작업  
  - 예: 개와 고양이를 구별하는 모델  

- **CNN (Convolutional Neural Network)**  
  - 이미지 데이터를 처리하는 인공 신경망  
  - 합성곱 연산을 사용하여 이미지 특징을 추출하고 분류 수행  

- **Feature Map**  
  - 합성곱 층을 통과하면서 추출된 이미지의 특징 정보  
  - 여러 개의 채널을 통해 다양한 특징 표현 가능  

- **Pooling**  
  - 특징 맵의 크기를 줄여 계산량을 줄이고, 중요한 특징을 유지하는 기법  
  - 대표적인 방법: 최대 풀링 (Max Pooling), 평균 풀링 (Average Pooling)  

- **Softmax Function**  
  - 다중 클래스 분류에서 출력 값을 확률로 변환하는 활성화 함수  
  - 모델이 특정 클래스에 속할 확률을 예측하는 역할 수행  

- **Transfer Learning**  
  - 사전 학습된 모델을 활용하여 새로운 데이터셋에 적응시키는 기법  
  - 기존 모델의 가중치를 일부 유지하고 특정 부분만 재학습  

- **Data Augmentation**  
  - 데이터 부족 문제를 해결하기 위해 이미지 변형을 통해 데이터셋을 확장하는 기법  
  - 회전, 확대, 축소, 좌우 반전 등의 방법 사용  

- **Overfitting (과적합)**  
  - 모델이 학습 데이터에는 잘 맞지만, 새로운 데이터에서는 성능이 저하되는 현상  
  - 데이터 증강, 정규화 기법, 드롭아웃 등을 사용하여 해결  

- **Batch Normalization**  
  - 신경망의 각 층에서 입력 데이터를 정규화하여 학습 속도를 향상시키는 기법  
  - 내부 공변량 변화(Internal Covariate Shift)를 줄여 훈련 안정성 증가  

- **Loss Function (손실 함수)**  
  - 모델의 예측값과 실제값 사이의 차이를 측정하는 함수  
  - 이미지 분류에서는 주로 교차 엔트로피 손실(Cross-Entropy Loss) 사용  

---

**3.2.2 객체 인식**  
- **객체 인식**  
  - 이미지 내에서 여러 개의 객체를 탐지하고 해당 객체의 위치를 식별하는 작업  
  - 예: 자율주행 차량이 도로 위의 보행자, 차량, 신호등을 탐지하는 모델  

- **Bounding Box**  
  - 객체의 위치를 나타내는 직사각형 영역  
  - 중심 좌표, 너비, 높이 등의 정보를 포함  

- **IoU (Intersection over Union)**  
  - 예측된 박스와 실제 정답 박스 사이의 겹치는 정도를 평가하는 지표  
  - 높은 IoU 값일수록 정확한 객체 검출  

- **Anchor Box**  
  - 다양한 크기의 객체를 탐지하기 위해 사전에 정의된 기준 박스  
  - 객체 크기에 맞춰 여러 개의 앵커 박스 설정  

- **R-CNN (Region-based CNN)**  
  - 이미지 내에서 후보 영역(Region Proposal)을 생성한 후, CNN을 통해 객체를 분류하는 기법  
  - Fast R-CNN, Faster R-CNN 등으로 발전  

- **YOLO (You Only Look Once)**  
  - 단일 신경망을 사용하여 한 번의 연산으로 객체의 위치와 클래스 예측  
  - 실시간 객체 검출에 적합  

- **SSD (Single Shot Multibox Detector)**  
  - YOLO와 유사한 방식으로, 여러 크기의 특징 맵을 사용하여 다양한 크기의 객체 검출  

- **Feature Pyramid Network (FPN)**  
  - 다양한 크기의 객체를 효과적으로 탐지하기 위해 여러 해상도의 특징 맵을 활용  

- **Non-Maximum Suppression (NMS)**  
  - 중복된 예측 박스를 제거하고 최적의 박스만 선택하는 알고리즘  

---

**3.2.3 스타일 전이**  
- **스타일 전이 (Style Transfer)**  
  - 특정 이미지의 스타일을 다른 이미지에 적용하여 새로운 이미지 생성  
  - 예: 고흐의 그림 스타일을 일반 사진에 적용하여 예술적 변환 수행  

- **Neural Style Transfer (NST)**  
  - 신경망을 사용하여 콘텐츠 이미지의 구조를 유지하면서 스타일 이미지의 패턴을 적용하는 기법  

- **Content Image**  
  - 스타일 변환의 대상이 되는 원본 이미지  
  - 스타일만 변경하고 싶은 사진  

- **Style Image**  
  - 원본 이미지에 적용할 스타일을 가진 이미지  
  - 명화, 특정 예술작품 등  

- **Gram Matrix**  
  - 스타일 정보를 표현하는 행렬  
  - 특징 맵 간의 상관관계를 분석하여 스타일 패턴 학습  

- **Perceptual Loss**  
  - 스타일 변환 시, 원본 이미지와 변환된 이미지 간의 차이를 줄이기 위한 손실 함수  
  - 콘텐츠 손실과 스타일 손실을 함께 고려  

- **DeepDream**  
  - 신경망의 내부 특징을 강조하여 환각적인 이미지 생성  

- **AdaIN (Adaptive Instance Normalization)**  
  - 콘텐츠 이미지의 통계값을 스타일 이미지의 통계값으로 정규화하여 빠르게 스타일 변환 수행  

- **GAN (Generative Adversarial Network)**  
  - 생성자와 판별자로 구성된 적대적 신경망을 활용하여 새로운 이미지를 생성하는 모델  

- **CycleGAN**  
  - 지도 학습 없이 두 개의 도메인 간 스타일 변환을 수행하는 모델  
  - 예: 사진을 그림으로 변환, 낮 사진을 밤 사진으로 변환  

추가적으로 필요한 개념이 있으면 요청해줘
