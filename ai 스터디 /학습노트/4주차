# 머신러닝 스터디 학습 노트

## 1. 결정 트리 (Decision Tree)

결정 트리는 데이터를 특정한 기준으로 분할하여 예측 모델을 생성하는 지도 학습 알고리즘이다. 
각 노드에서 특정 특성을 기준으로 데이터를 나누며, 최종적으로 리프 노드에서 예측 결과를 제공한다.

### 특징
- 직관적이며 해석이 용이함
- 분류와 회귀 모두 가능
- 과적합 가능성이 높음

### 주요 하이퍼파라미터
- max_depth: 트리의 최대 깊이 제한
- min_samples_split: 노드를 분할하기 위한 최소 샘플 수
- criterion: 분할 기준 (Gini 불순도, 엔트로피 등)

## 2. 교차 검증과 그리드 서치

교차 검증은 모델의 일반화 성능을 평가하기 위해 데이터를 여러 개의 폴드로 나누어 학습과 검증을 반복하는 기법이다.

### 방법
- K-폴드 교차 검증: 데이터를 K개의 폴드로 나누어 각각의 폴드를 검증용 데이터로 순차적으로 사용
- LOOCV: 하나의 샘플을 검증 데이터로 사용하고 나머지를 학습 데이터로 활용

### 그리드 서치
하이퍼파라미터 조합을 탐색하여 최적의 모델을 찾는 방법

- param_grid: 하이퍼파라미터 후보군 설정
- cv: 교차 검증 횟수 지정
- scoring: 성능 평가 기준 (정확도, F1-score 등)

## 3. 트리 기반 앙상블 기법

트리 기반 앙상블은 여러 개의 트리 모델을 조합하여 성능을 높이는 기법이다.

### 랜덤 포레스트
- 여러 개의 결정 트리를 활용하여 예측 수행
- 무작위로 선택된 특성과 샘플을 사용하여 학습
- 과적합 방지 및 일반화 성능 향상

### 엑스트라 트리
- 랜덤 포레스트와 유사하지만 더 많은 랜덤성 적용
- 노드 분할 시 최적의 기준 없이 무작위로 분할 수행

### 그레이디언트 부스팅
- 이전 트리의 오차를 보완하면서 학습
- 학습률을 조정하여 최적화 가능
- 계산 비용이 높지만 높은 성능 제공

### 히스토그램 기반 그레이디언트 부스팅
- 데이터를 히스토그램 형태로 그룹화하여 연산 속도 개선
- LightGBM, XGBoost 등의 라이브러리에서 사용됨

## 4. 학습 요약

결정 트리: 해석 용이, 직관적, 과적합 위험

랜덤 포레스트: 일반화 성능 우수, 계산 비용 증가

엑스트라 트리: 랜덤성 증가로 일반화 가능, 결과 해석 어려움

그레이디언트 부스팅: 높은 예측 성능, 계산량 많음

히스토그램 기반 GB: 속도 빠름, 최적 하이퍼파라미터 탐색 필요

