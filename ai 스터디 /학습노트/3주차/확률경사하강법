• 확률적 경사 하강법은 훈련 세트에서 샘플 하나씩 꺼내 손실 함수의 경사를 따라 최적의 모델을
찾는 알고리즘입니다. 샘플을 하나씩 사용하지 않고 여러 개를 사용하면 미니배치 경사 하강법
이 됩니다. 한 번에 전체 샘플을 사용하면 배치 경사 하강법이 됩니다.
• 손실 함수는 확률적 경사 하강법이 최적화할 대상입니다. 대부분의 문제에 잘 맞는 손실 함수
가 이미 정의되어 있습니다. 이진 분류에는 로지스틱 회귀 （또는 이진 크로스엔트로피） 손실
함수를 사용합니다. 다중 분류에는 크로스엔트로피 손실 함수를 사용합니다. 회귀 문제에는 평
균 제곱 오차 손실 함수를 사용합니 다.
• 에포크는 확률적 경사 하강법에서 전체 샘플을 모두 사용하는 한 번 반복을 의미합니다. 일반
적으로 경사 하강법 알고리즘은 수십에서 수백 번의 에포크를 반복합니다.

scikit-learn
머신러닝 216 Chapter 04 I 다양한 분류 알고리즘
• SGDCIassifier는 확률적 경사 하강법을 사용한 분류 모델을 만듭니다.
loss 매개변수는 확률적 경사 하강법으로 최적화할 손실 함수를 지정합니다. 기본값은 서포트
벡터 머신을 위한 ‘hinge’ 손실 함수입니다. 로지스틱 회귀를 위해서는 log’로 지정합니다.
penalty 매개변수에서 규제의 종류를 지정할 수 있습니다. 기본값은 L2 규제를 위한 ‘12’입니
다. L1 규제를 적용하려면 ‘11’로 지정합니다. 규제 강도는 alpha 매개변수에서 지정합니다.
기본값은 0.00이입니다.
maxjter 매개변수는 에포크 횟수를 지정합니다. 기본값은 1000입니다.
tol 매개변수는 반복을 멈출 조건입니다. n_iter_no_change 매개변수에서 지정한 에포크 동
안 손실이 tol 만큼 줄어들지 않으면 알고리즘이 중단됩니다. tol 매개변수의 기본값은 0.001
이고 n_iter_no_change 매개변수의 기본값은 5입니다.

• SGDRegressor는 확률적 경사 하강법을 사용한 회귀 모델을 만듭니다.
loss 매개변수에서 손실 함수를 지정합니다. 기본값은 제곱 오차를 나타내는 squaredjoss’
입니다.
앞의 SGDCIassifier에서 설명한 매개변수는 모두 SGDRegressor에서 동일하게 사용됩
니다.
