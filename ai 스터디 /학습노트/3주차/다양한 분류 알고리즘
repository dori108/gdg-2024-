• 로지스틱 회귀는 선형 방정식을 사용한 분류 알고리즘입니다. 선형 회귀와 달리 시그모이드 함
수나 소프트맥스 함수를 사용하여 클래스 확률을 출력할 수 있습니 다.
• 다중 분류는 타깃 클래스가 2개 이상인 분류 문제입니다. 로지스틱 회귀는 다중 분류를 위해
소프트맥스 함수를 사용하여 클래스를 예측합니다.
• 시그모이드 함수는 선형 방정식의 출력을 0과 1 사이의 값으로 압축하며 이진 분류를 위해 사
용합니다.
• 소프트맥스 함수는 다중 분류에서 여러 선형 방정식의 출력 결과를 정규화하여 합이 1이 되도
록만듭니다.


scikit-learn
• LogisticRegression은 선형 분류 알고리즘인 로지스틱 회귀를 위한클래스입니다.
solver 매개변수에서 사용할 알고리즘을 선택할 수 있습니다. 기본값은 ‘Ibfgs’입니다. 사이킷
런 0.17 버전에 추가된 ‘sag’는 확률적 평균 경사 하강법 알고리즘으로 특성과 샘플 수가 많을
때 성능은 빠르고 좋습니다. 사이킷런 0.19 버전에는 ‘sag’의 개선 버전인 ‘saga’가 추가되었
습니다.
penalty 매개변수에서 L2 규제 （릿지 방식）와 L1 규제 （라쏘 방식）를 선택할 수 있습니다. 기
본값은 L2 규제를 의미하는 ‘12’입니다.
C 매개변수에서 규제의 강도를 제어합니다. 기본값은 1.0이며 값이 작을수록 규제가 강해집
니다.


• predict_proba() 메서드는 예측 확률을 반환합니다.
이진 분류의 경우에는 샘플마다 음성 클래스와 양성 클래스에 대한 확률을 반환합니다.
다중 분류의 경우에는 샘플마다 모든 클래스에 대한 확률을 반환합니다.
• decision_function()은 모델이 학습한 선형 방정식의 출력을 반환합니다.
이진 분류의 경우 양성 클래스의 확률이 반환됩니다. 이 값이 0보다 크면 양성 클래스, 직거나
같으면 음성 클래스로 예측합니다.
다중 분류의 경우 각 클래스마다 선형 방정식을 계산합니다. 가장 큰 값의 클래스가 예측 클래
스가 됩니다.
